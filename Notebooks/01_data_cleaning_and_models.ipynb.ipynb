{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules or \"COLAB_RELEASE_TAG\" in os.environ\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Mount Google Drive (only in Colab)\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    ROOT = Path(\"/content/drive/MyDrive/Colab Notebooks/Final Project\")\n",
        "else:\n",
        "    # Local dev: assume repo structure\n",
        "    ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"Notebooks\") else Path.cwd()\n",
        "\n",
        "DATA_DIR = ROOT / \"Data\"\n",
        "REPORTS_DIR = ROOT / \"Reports\"\n",
        "ARTIFACTS_DIR = ROOT / \"artifacts\"\n",
        "\n",
        "REPORTS_DIR.mkdir(exist_ok=True, parents=True)\n",
        "ARTIFACTS_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Example usage\n",
        "# df = pd.read_csv(DATA_DIR / \"real_estate.csv\")\n"
      ],
      "metadata": {
        "id": "R8nSBz2mENsO",
        "outputId": "2057004d-bb41-40c8-9297-2b884255d96a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "R8nSBz2mENsO",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bdAw796UXtjV",
      "metadata": {
        "id": "bdAw796UXtjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "002f8fc5-556f-47ae-d965-5975b5706080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks/Final Project\n"
          ]
        }
      ],
      "source": [
        "#RUN CELL ONLY WHEN GOOGLE COLAB USED\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive/Colab Notebooks/Final Project/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6Xx_X5FFkeUf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xx_X5FFkeUf",
        "outputId": "afe4493c-4157-4774-8295-98640930db90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dmba\n",
            "  Downloading dmba-0.2.4-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from dmba) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from dmba) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from dmba) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from dmba) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from dmba) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from dmba) (1.16.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->dmba) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->dmba) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->dmba) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->dmba) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->dmba) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->dmba) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->dmba) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->dmba) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->dmba) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->dmba) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->dmba) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->dmba) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->dmba) (1.17.0)\n",
            "Downloading dmba-0.2.4-py3-none-any.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dmba\n",
            "Successfully installed dmba-0.2.4\n",
            "Colab environment detected.\n"
          ]
        }
      ],
      "source": [
        "#Importing required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.neighbors import KNeighborsRegressor # KNN for regression\n",
        "from sklearn.model_selection import GridSearchCV ,cross_val_score# For hyperparameter tuning\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error, r2_score # For model evaluation\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "!pip install dmba\n",
        "from dmba import regressionSummary, backward_elimination, AIC_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2dfd56ba-ace7-41d2-93a3-7be7bf50d220",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "2dfd56ba-ace7-41d2-93a3-7be7bf50d220",
        "outputId": "6cffde15-518f-4475-b7da-1263b8301d6e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Real estate.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-641274193.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# STEP 1: LOAD AND PREVIEW DATA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhouseprice_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Real estate.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhouseprice_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Note:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Real estate.csv'"
          ]
        }
      ],
      "source": [
        "# STEP 1: LOAD AND PREVIEW DATA\n",
        "houseprice_df = pd.read_csv('Real estate.csv')\n",
        "houseprice_df.head()\n",
        "\n",
        "#Note:\n",
        "#No: Transaction ID\n",
        "#X1 transaction date: Date of the house purchase\n",
        "#X2 house age: The age of the house in months\n",
        "#X3 distance to the nearest MRT station: Distance to nearest MRT station in meters\n",
        "#X4 number of convenience stores: Number of convenience stores near the house\n",
        "#X5 latitude: Latitude of the house location\n",
        "#X6 longitude: Longitude of the house location\n",
        "#Y house price of unit area: House price per unit area"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j1xGmNgQfcsH",
      "metadata": {
        "id": "j1xGmNgQfcsH"
      },
      "outputs": [],
      "source": [
        "#STEP 2: DATA CLEANING AND PREPARATION\n",
        "#Display dimensions of data frame\n",
        "houseprice_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a33ddd6a-5824-4625-9224-098b49efaff8",
      "metadata": {
        "id": "a33ddd6a-5824-4625-9224-098b49efaff8"
      },
      "outputs": [],
      "source": [
        "# Fixing inconsistent formatting\n",
        "houseprice_df.columns = houseprice_df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
        "\n",
        "# Rename 'no' column to 'transaction_id'\n",
        "houseprice_df.rename(columns={'no': 'transaction_id'}, inplace=True)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "houseprice_df.head(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0cffd2d-657b-43f0-af53-a72895250d95",
      "metadata": {
        "id": "e0cffd2d-657b-43f0-af53-a72895250d95"
      },
      "outputs": [],
      "source": [
        "# Checking for missing values in each column\n",
        "houseprice_df.isnull().sum()\n",
        "\n",
        "#Note: No missing values found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b848e4a4-c28b-4dba-b32e-8e3d95dd6dc2",
      "metadata": {
        "id": "b848e4a4-c28b-4dba-b32e-8e3d95dd6dc2"
      },
      "outputs": [],
      "source": [
        "# Checking for duplicate rows\n",
        "print(\"\\nDuplicate rows found:\")\n",
        "houseprice_df.duplicated().sum()\n",
        "\n",
        "#Note: No duplicate records found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9b301a5-ba77-4ea6-98cb-4049e9e8b3b4",
      "metadata": {
        "id": "e9b301a5-ba77-4ea6-98cb-4049e9e8b3b4"
      },
      "outputs": [],
      "source": [
        "# Checking for data types\n",
        "houseprice_df.dtypes\n",
        "\n",
        "#Note: All column's datatypes are appropriate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51fea94d-755a-46fd-963b-a114d5a23fcd",
      "metadata": {
        "id": "51fea94d-755a-46fd-963b-a114d5a23fcd"
      },
      "outputs": [],
      "source": [
        "# Checking Outliers and Data Distribution\n",
        "# Display descriptive statistics to get an overview of the data\n",
        "# distribution and identify potential outliers (e.g., min/max values far from quartiles).\n",
        "print(\"\\n--- Descriptive Statistics of Numerical Columns ---\")\n",
        "print(houseprice_df.describe())\n",
        "\n",
        "#Note: \"x3_distance_to_the_nearest_mrt_station\" and \"y_house_price_of_unit_area\" variables seemingly have outliers based on their min and max\n",
        "#values respectively. 'transaction_id' and 'x1_transaction_date' columns are ignored because the former is not a potential predictor of the house\n",
        "#price variable and the latter is a potential predictor but has notable inconsistent and inaccuracte data. Hence, instead of this varible we will\n",
        "#consider 'x2_house_age' variable because it is saying the same story as transaction date variable but is more accurate and consistent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4edfe1ec-a2aa-48b3-a27f-6b6c79806003",
      "metadata": {
        "id": "4edfe1ec-a2aa-48b3-a27f-6b6c79806003"
      },
      "outputs": [],
      "source": [
        "# Graphical representation of outliers to confirm outlier detection for \"x3_distance_to_the_nearest_mrt_station\" and \"y_house_price_of_unit_area\" variables\n",
        "#And checking for potential outliers in other variables\n",
        "columns_to_plot = ['x2_house_age','x3_distance_to_the_nearest_mrt_station','x4_number_of_convenience_stores','x5_latitude','x6_longitude', 'y_house_price_of_unit_area']\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Create one boxplot per column\n",
        "for i, col in enumerate(columns_to_plot):\n",
        "    ax = plt.subplot(2, 3, i + 1)\n",
        "    sns.boxplot(y=houseprice_df[col], color=\"skyblue\", ax=ax)\n",
        "    ax.set_title(f'Boxplot: {col}', fontsize=10)\n",
        "    ax.set_ylabel('')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#Note: 'x3_distance_to_the_nearest_mrt_station','x5_latitude','x6_longitude', 'y_house_price_of_unit_area' variables are confirmed to have outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lWZdlH6T8uC9",
      "metadata": {
        "id": "lWZdlH6T8uC9"
      },
      "outputs": [],
      "source": [
        "#Count the outliers in each of the columns\n",
        "# Function to count outliers using IQR method\n",
        "# Updated function to return outlier values\n",
        "def get_outliers(series):\n",
        "    Q1 = series.quantile(0.25)\n",
        "    Q3 = series.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = series[(series < lower_bound) | (series > upper_bound)]\n",
        "    return outliers\n",
        "\n",
        "# Apply to selected columns\n",
        "for col in ['x3_distance_to_the_nearest_mrt_station', 'x5_latitude', 'x6_longitude', 'y_house_price_of_unit_area']:\n",
        "    outliers = get_outliers(houseprice_df[col])\n",
        "    print(f\"\\nNumber of outliers in {col}: {outliers.count()}\")\n",
        "    print(f\"Outlier values in {col}:\\n{outliers.values}\")\n",
        "\n",
        "#Outliers Handling:\n",
        "#'x5_latitude' and 'x6_longitude' columns have outliers but they are valid values for location of the houses. Removing or altering\n",
        "#them can distort information and analysis. Hence, the outliers of these two variables will remain in the dataset without any changes.\n",
        "#Other 2 outliers will be handled in the upcoming 2 code cells:\n",
        "#The outliers in 'x3_distance_to_the_nearest_mrt_station' column will be handled through winsorizing(capping) to reduce extreme impact but keep the\n",
        "#data points valid and the outliers in 'y_house_price_of_unit_area' column will be eliminated from dataset since the outliers are very few(3)in number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k1IVepkuITEi",
      "metadata": {
        "id": "k1IVepkuITEi"
      },
      "outputs": [],
      "source": [
        "# Function to cap values above a specified upper percentile for 'x3_distance_to_the_nearest_mrt_station' column\n",
        "def cap_outliers(series, upper_percentile=0.97):\n",
        "    upper_bound = series.quantile(upper_percentile)\n",
        "    return series.clip(upper=upper_bound)\n",
        "\n",
        "# Apply capping\n",
        "houseprice_df['x3_distance_to_the_nearest_mrt_station'] = cap_outliers(houseprice_df['x3_distance_to_the_nearest_mrt_station'])\n",
        "print(f\"{'x3_distance_to_the_nearest_mrt_station'}: capped at 97th percentile = {houseprice_df['x3_distance_to_the_nearest_mrt_station'].max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JRThXrwzNqN3",
      "metadata": {
        "id": "JRThXrwzNqN3"
      },
      "outputs": [],
      "source": [
        "#Remove records with outliers in 'y_house_price_of_unit_area' column\n",
        "# Define outlier values to remove\n",
        "outlier_values = [78.3, 117.5, 78.0]\n",
        "\n",
        "# Remove rows where 'y_house_price_of_unit_area' has these values\n",
        "houseprice_df = houseprice_df[~houseprice_df['y_house_price_of_unit_area'].isin(outlier_values)]\n",
        "\n",
        "# Confirm removal\n",
        "print(\"Remaining rows after removing outliers:\", len(houseprice_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yqqZb-tdSIal",
      "metadata": {
        "id": "yqqZb-tdSIal"
      },
      "outputs": [],
      "source": [
        "# STEP 3: DATA ANALYSIS FOR DATA UNDERSTANDING\n",
        "#Display descriptive statistics of the variables\n",
        "houseprice_df.describe()\n",
        "\n",
        "#Inference: We can understand various aspects about each of the variables such as count, mean, std, min, 25% quartile, 50% quartile, 75% quartile and max values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Yq-kl7iJpIUf",
      "metadata": {
        "id": "Yq-kl7iJpIUf"
      },
      "outputs": [],
      "source": [
        "# Plotting the boxplot for house price per unit area\n",
        "mean = np.mean(houseprice_df['y_house_price_of_unit_area'])\n",
        "q1 = np.percentile(houseprice_df['y_house_price_of_unit_area'], 25)\n",
        "q3 = np.percentile(houseprice_df['y_house_price_of_unit_area'], 75)\n",
        "min_val = np.min(houseprice_df['y_house_price_of_unit_area'])\n",
        "max_val = np.max(houseprice_df['y_house_price_of_unit_area'])\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.boxplot(x=houseprice_df['y_house_price_of_unit_area'], color='skyblue',)\n",
        "plt.title('Boxplot of House Price per Unit Area')\n",
        "plt.xlabel('House Price per Unit Area')\n",
        "plt.grid(True)\n",
        "plt.text(mean, 0.05, f'Mean: {mean:.2f}', ha='center', va='top', color='red', fontweight='bold')\n",
        "plt.text(q1, 0.05, f'Q1: {q1:.2f}', ha='center', va='bottom', color='green')\n",
        "plt.text(q3, 0.05, f'Q3: {q3:.2f}', ha='center', va='bottom', color='blue')\n",
        "plt.text(min_val, -0.05, f'Min: {min_val:.2f}', ha='center', va='top', color='purple')\n",
        "plt.text(max_val, -0.05, f'Max: {max_val:.2f}', ha='center', va='top', color='brown')\n",
        "plt.show()\n",
        "\n",
        "#Inference:The boxplot of 411 observations shows a mean of 37.98.\n",
        "#A wide range from 7.6 to 117.5 indicates significant variability, while the interquartile range of 18.9 highlights diverse mid-range prices.\n",
        "#In this case, the outliers are anything above upper quartile(75). The existence of outliers suggest right skewness, revealing a few highly\n",
        "#priced properties that create disparities in the housing market and affect overall price distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7836753e-b71e-4cda-9f0f-b4f77d0c1d9e",
      "metadata": {
        "id": "7836753e-b71e-4cda-9f0f-b4f77d0c1d9e"
      },
      "outputs": [],
      "source": [
        "# Generating and plotting the correlation matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "corr_matrix = houseprice_df.corr(numeric_only=True)\n",
        "\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
        "plt.title(\"Correlation Heatmap of Numeric Variables\")\n",
        "plt.show()\n",
        "\n",
        "#Inference: \"transaction_id\" and \"x1_transaction_date\" have low correlation with outcome variable \"y_house_price_of_unit_area\". Hence, we will NOT\n",
        "# be considering these two variables during variable selection for any of the model building process. \"x2_house_age\" have moderate correlation with outcome\n",
        "#variable while all the other potential predictors which are \"x3_distance_to_the_nearest_mrt_station\", \"x4_number_of_convenience_stores\",\n",
        "#\"x5_latitude\" and \"x6_longitude\" have moderate to high correlation with outcome variable. Hence, the remaining variables will be considered during\n",
        "#variable selection in the model building processes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tMxC4CT-qARH",
      "metadata": {
        "id": "tMxC4CT-qARH"
      },
      "outputs": [],
      "source": [
        "#Removing \"transaction_id\" and \"x1_transaction_date\" columns from houseprice_df\n",
        "houseprice_df = houseprice_df.drop(columns=['transaction_id', 'x1_transaction_date'])\n",
        "houseprice_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QNJjNCrFr-gD",
      "metadata": {
        "id": "QNJjNCrFr-gD"
      },
      "outputs": [],
      "source": [
        "#STEP 4: PREDICTIVE MODELLING\n",
        "#Model 1: Linear Regression\n",
        "#Defining predictors and outcome variables for variable selection through backward elimination\n",
        "predictors = ['x2_house_age', 'x3_distance_to_the_nearest_mrt_station', 'x4_number_of_convenience_stores', 'x5_latitude', 'x6_longitude']\n",
        "outcome = 'y_house_price_of_unit_area'\n",
        "\n",
        "#Partition data into predictors (x) and output (y)\n",
        "X = houseprice_df[predictors]\n",
        "y = houseprice_df[outcome]\n",
        "\n",
        "#Split the data into training and validation datasets. Validation dataset size is 40% of the input datasize\n",
        "train_X, valid_X, train_y, valid_y = train_test_split(X,y,test_size=0.4,random_state=1)\n",
        "\n",
        "#Backward elimination for variable selection\n",
        "def train_model(variables):\n",
        "  model = LinearRegression()\n",
        "  model.fit(train_X[variables], train_y)\n",
        "  return model\n",
        "def score_model(model, variables):\n",
        "  return AIC_score(train_y, model.predict(train_X[variables]), model)\n",
        "best_model, best_variables = backward_elimination(train_X.columns, train_model, score_model, verbose=True)\n",
        "print(best_variables)\n",
        "\n",
        "#The optimal parameters are chosen by backward elimination process for this linear regression model/algorithm. The model stats with all available\n",
        "#features and it iteratively removes the least significant features using AIC score (Akaike Information Criterion). Once every remaining features\n",
        "#are significant, the model stops the process and gives the list of \"best variables\" where all features are significant in predicting the outcome\n",
        "#variable which is \"house price of unit area\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xYjnACYQKJGV",
      "metadata": {
        "id": "xYjnACYQKJGV"
      },
      "outputs": [],
      "source": [
        "#Train model on \"best_variables\"\n",
        "best_model.fit(train_X[best_variables], train_y)\n",
        "\n",
        "#Print coefficients of the selected variables(best_variables)\n",
        "for var, coef in zip(best_variables, best_model.coef_):\n",
        "  print(f\"{var}: {coef}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4I6pT7smVgCo",
      "metadata": {
        "id": "4I6pT7smVgCo"
      },
      "outputs": [],
      "source": [
        "#Training Data: Predicting using predictor variables selected in backward elimination process\n",
        "pred_y = best_model.predict(train_X[best_variables])\n",
        "regressionSummary(train_y, pred_y)\n",
        "\n",
        "result = pd.DataFrame({'Predicted': pred_y,'Actual': train_y,'Residual': train_y - pred_y})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vcWyJIA1zFnh",
      "metadata": {
        "id": "vcWyJIA1zFnh"
      },
      "outputs": [],
      "source": [
        "# Plot Actual vs Predicted for training data\n",
        "plt.figure()\n",
        "sns.scatterplot(x=train_y, y=pred_y)\n",
        "plt.plot([train_y.min(), train_y.max()], [train_y.min(), train_y.max()], 'r--')\n",
        "plt.title(\" Training Data: Actual vs Predicted (Linear Regression)\")\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I7z_1UpsgZOM",
      "metadata": {
        "id": "I7z_1UpsgZOM"
      },
      "outputs": [],
      "source": [
        "#Plot the actual, predicted and residuals of training data\n",
        "fig, ax = plt.subplots()\n",
        "ax = train_y.hist()\n",
        "ax.set_xlabel('House Price Per Unit Area')\n",
        "plt.title(\"Actual Training Data Distribution - Linear Regression\")\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax = result['Predicted'].hist()\n",
        "ax.set_xlabel('House Price Per Unit Area')\n",
        "plt.title(\"Predicted Training Data Distribution - Linear Regression\")\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax = result['Residual'].hist()\n",
        "ax.set_xlabel('Residuals')\n",
        "plt.title(\"Residuals Distribution - Linear Regression\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BUnbRLPaVAlU",
      "metadata": {
        "id": "BUnbRLPaVAlU"
      },
      "outputs": [],
      "source": [
        "#Validation Data: Predicting using predictor variables selected in backward elimination process\n",
        "pred_y = best_model.predict(valid_X[best_variables])\n",
        "regressionSummary(valid_y, pred_y)\n",
        "\n",
        "result = pd.DataFrame({'Predicted': pred_y,'Actual': valid_y,'Residual': valid_y - pred_y})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1sxiDTiQ0Kye",
      "metadata": {
        "id": "1sxiDTiQ0Kye"
      },
      "outputs": [],
      "source": [
        "# Plot Actual vs Predicted for validation data\n",
        "plt.figure()\n",
        "sns.scatterplot(x=valid_y, y=pred_y)\n",
        "plt.plot([valid_y.min(), valid_y.max()], [valid_y.min(), valid_y.max()], 'r--')\n",
        "plt.title(\" Validation Data: Actual vs Predicted (Linear Regression)\")\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r6JsQySDgijd",
      "metadata": {
        "id": "r6JsQySDgijd"
      },
      "outputs": [],
      "source": [
        "#Plot the actual, predicted and residuals of validation data\n",
        "fig, ax = plt.subplots()\n",
        "ax = valid_y.hist()\n",
        "ax.set_xlabel('House Price Per Unit Area')\n",
        "plt.title(\"Actual Validation Data Distribution - Linear Regression\")\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax = result['Predicted'].hist()\n",
        "ax.set_xlabel('House Price Per Unit Area')\n",
        "plt.title(\"Predicted Validation Data Distribution - Linear Regression\")\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax = result['Residual'].hist()\n",
        "ax.set_xlabel('Residuals')\n",
        "plt.title(\"Residuals Distribution - Linear Regression\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NM-XmI9yyj0d",
      "metadata": {
        "id": "NM-XmI9yyj0d"
      },
      "outputs": [],
      "source": [
        "#Model 2: Random Forest Regressor\n",
        "#Defining predictors and outcome variables for variable selection through RFECV\n",
        "predictors = ['x2_house_age', 'x3_distance_to_the_nearest_mrt_station', 'x4_number_of_convenience_stores', 'x5_latitude', 'x6_longitude']\n",
        "outcome = 'y_house_price_of_unit_area'\n",
        "\n",
        "#Partition data into predictors (x) and output (y)\n",
        "X = houseprice_df[predictors]\n",
        "y = houseprice_df[outcome]\n",
        "\n",
        "#Split the data into training and validation datasets. Validation dataset size is 40% of the input datasize\n",
        "train_X, valid_X, train_y, valid_y = train_test_split(X,y,test_size=0.4,random_state=1)\n",
        "\n",
        "# Define the best parameters for the Random Forest model\n",
        "best_params = {\n",
        "    \"n_estimators\": 150,\n",
        "    \"max_depth\": 10,\n",
        "    \"min_samples_split\": 8,\n",
        "    \"min_samples_leaf\": 2,\n",
        "    \"max_features\": 'sqrt'\n",
        "}\n",
        "\n",
        "# Initialize Random Forest Regressor with reasonable params\n",
        "rf = RandomForestRegressor(**best_params, random_state=42)\n",
        "\n",
        "# RFECV: Recursive feature elimination with cross-validation for variable selection\n",
        "rfecv = RFECV(\n",
        "    estimator=rf,\n",
        "    step=1,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit RFECV on training data\n",
        "rfecv.fit(train_X, train_y)\n",
        "\n",
        "# Get the variables selected through RFECV\n",
        "selected_features = train_X.columns[rfecv.support_]\n",
        "print(\"Optimal number of features:\", rfecv.n_features_)\n",
        "print(\"Selected features:\", list(selected_features))\n",
        "\n",
        "# The optimal features are chosen by the RFECV process using a Random Forest model.\n",
        "# The model starts with all available features and iteratively removes the least important features based on feature importance.\n",
        "# At each step, the model performance is evaluated using 5-fold cross-validation with mean squared error as the metric.\n",
        "# This process continues until the subset of features that gives the best cross-validated performance is found.\n",
        "# The final list of selected features are those that contribute most to accurately predicting the outcome variable,\n",
        "# which is the \"house price of unit area\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6Kuu0aVcILjC",
      "metadata": {
        "id": "6Kuu0aVcILjC"
      },
      "outputs": [],
      "source": [
        "#Train model on \"selected_features\"\n",
        "rf.fit(train_X[selected_features], train_y)\n",
        "\n",
        "# Create a DataFrame for feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    \"Feature\": houseprice_df[predictors].columns,\n",
        "    \"Importance\": rf.feature_importances_\n",
        "})\n",
        "\n",
        "feature_importance = feature_importance.sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "# Plot bar chart for feature importance\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(feature_importance[\"Feature\"], feature_importance[\"Importance\"], color=\"skyblue\")\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.title(\"Feature Importance in Random Forest Regressor Model\")\n",
        "plt.gca().invert_yaxis()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AhbNf0pfA5Ad",
      "metadata": {
        "id": "AhbNf0pfA5Ad"
      },
      "outputs": [],
      "source": [
        "#Training Data: Predicting using \"selected_features\"\n",
        "pred_y = rf.predict(train_X[selected_features])\n",
        "regressionSummary(train_y, pred_y)\n",
        "\n",
        "result = pd.DataFrame({'Predicted': pred_y,'Actual': train_y,'Residual': train_y - pred_y})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_WsAWXA61hIV",
      "metadata": {
        "id": "_WsAWXA61hIV"
      },
      "outputs": [],
      "source": [
        "# Plot Actual vs Predicted for training data\n",
        "plt.figure()\n",
        "sns.scatterplot(x=train_y, y=pred_y)\n",
        "plt.plot([train_y.min(), train_y.max()], [train_y.min(), train_y.max()], 'r--')\n",
        "plt.title(\" Training Data: Actual vs Predicted (Random Forest Regressor)\")\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yaqTzhVPgnFz",
      "metadata": {
        "id": "yaqTzhVPgnFz"
      },
      "outputs": [],
      "source": [
        "#Plot the actual, predicted and residuals of training data\n",
        "fig, ax = plt.subplots()\n",
        "ax = train_y.hist()\n",
        "ax.set_xlabel('House Price Per Unit Area')\n",
        "plt.title(\"Actual Training Data Distribution - Random Forest Regressor\")\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax = result['Predicted'].hist()\n",
        "ax.set_xlabel('House Price Per Unit Area')\n",
        "plt.title(\"Predicted Training Data Distribution - Random Forest Regressor\")\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax = result['Residual'].hist()\n",
        "ax.set_xlabel('Residuals')\n",
        "plt.title(\"Residuals Distribution - Random Forest Regressor\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SKgf5RqWEyyb",
      "metadata": {
        "id": "SKgf5RqWEyyb"
      },
      "outputs": [],
      "source": [
        "#Validation Data: Predicting using \"selected_features\"\n",
        "pred_y = rf.predict(valid_X[selected_features])\n",
        "regressionSummary(valid_y, pred_y)\n",
        "\n",
        "result = pd.DataFrame({'Predicted': pred_y,'Actual': valid_y,'Residual': valid_y - pred_y})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u_ZPwXuf16Z0",
      "metadata": {
        "id": "u_ZPwXuf16Z0"
      },
      "outputs": [],
      "source": [
        "# Plot Actual vs Predicted for validation data\n",
        "plt.figure()\n",
        "sns.scatterplot(x=valid_y, y=pred_y)\n",
        "plt.plot([valid_y.min(), valid_y.max()], [valid_y.min(), valid_y.max()], 'r--', label = \"Regression Line\")\n",
        "plt.title(\" Validation Data: Actual vs Predicted (Random Forest Regressor)\")\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_KWQdyu0gzcz",
      "metadata": {
        "id": "_KWQdyu0gzcz"
      },
      "outputs": [],
      "source": [
        "#Plot the actual, predicted and residuals of validation data\n",
        "fig, ax = plt.subplots()\n",
        "ax = valid_y.hist()\n",
        "ax.set_xlabel('House Price Per Unit Area')\n",
        "plt.title(\"Actual Validation Data Distribution - Random Forest Regressor\")\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax = result['Predicted'].hist()\n",
        "ax.set_xlabel('House Price Per Unit Area')\n",
        "plt.title(\"Predicted Validation Data Distribution - Random Forest Regressor\")\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax = result['Residual'].hist()\n",
        "ax.set_xlabel('Residuals')\n",
        "plt.title(\"Residuals Distribution - Random Forest Regressor\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6aeabf2-9c66-4bad-83d1-d41c43e85c84",
      "metadata": {
        "id": "d6aeabf2-9c66-4bad-83d1-d41c43e85c84"
      },
      "outputs": [],
      "source": [
        "#Model 3: K-Nearest Neighbors (KNN)\n",
        "# Define predictors and outcome\n",
        "predictors = ['x2_house_age', 'x3_distance_to_the_nearest_mrt_station',\n",
        "              'x4_number_of_convenience_stores', 'x5_latitude', 'x6_longitude']\n",
        "outcome = 'y_house_price_of_unit_area'\n",
        "\n",
        "# Split original data into train and validation sets\n",
        "train_data, valid_data = train_test_split(houseprice_df, test_size=0.4, random_state=1)\n",
        "\n",
        "# Fit scalers separately for predictors and outcome on training data only\n",
        "X_scaler = StandardScaler()\n",
        "y_scaler = StandardScaler()\n",
        "\n",
        "# Fit on training data\n",
        "X_scaler.fit(train_data[predictors])\n",
        "y_scaler.fit(train_data[[outcome]])\n",
        "\n",
        "# Normalize full dataset (but based on training scalers only)\n",
        "house_norm = pd.DataFrame(\n",
        "    X_scaler.transform(houseprice_df[predictors]),\n",
        "    columns=[f'z_{col}' for col in predictors],\n",
        "    index=houseprice_df.index\n",
        ")\n",
        "\n",
        "# Add normalized outcome\n",
        "house_norm['z_' + outcome] = y_scaler.transform(houseprice_df[[outcome]])\n",
        "\n",
        "# Retrieve normalized train and validation sets using original split indices\n",
        "trainNorm = house_norm.loc[train_data.index]\n",
        "validNorm = house_norm.loc[valid_data.index]\n",
        "\n",
        "# Define normalized predictors and target\n",
        "normalized_predictors = [f'z_{col}' for col in predictors]\n",
        "normalized_outcome = f'z_{outcome}'\n",
        "\n",
        "# Partition the normalized data\n",
        "train_X = trainNorm[normalized_predictors]\n",
        "train_y = trainNorm[normalized_outcome]\n",
        "valid_X = validNorm[normalized_predictors]\n",
        "valid_y = validNorm[normalized_outcome]\n",
        "\n",
        "print(\"Train shape:\", train_X.shape, train_y.shape)\n",
        "print(\"Validation shape:\", valid_X.shape, valid_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a371e21c-ec39-466f-bf5a-441ec30576df",
      "metadata": {
        "id": "a371e21c-ec39-466f-bf5a-441ec30576df"
      },
      "outputs": [],
      "source": [
        "# Variable selection using GridSearchCV\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('select', SelectKBest(score_func=f_regression)),\n",
        "    ('knn', KNeighborsRegressor())\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'select__k': [2, 3, 4, 5],            # Try selecting 2 to 5 top features\n",
        "    'knn__n_neighbors': [2, 3, 5, 7, 10]  # Try different k values for KNN\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid.fit(train_X, train_y)\n",
        "\n",
        "print(\"Best number of features:\", grid.best_params_['select__k'])\n",
        "print(\"Best K value for KNN:\", grid.best_params_['knn__n_neighbors'])\n",
        "print(\"Best CV score (neg MSE):\", grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce80304c-478e-41bb-93b2-91e183eca49f",
      "metadata": {
        "id": "ce80304c-478e-41bb-93b2-91e183eca49f"
      },
      "outputs": [],
      "source": [
        "# Refit with best parameters\n",
        "best_k = grid.best_params_['select__k']\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "# Save feature names before passing into the pipeline\n",
        "feature_names = train_X.columns.tolist()\n",
        "\n",
        "# Fit the selector on the full training set to view the selected features\n",
        "selector = best_model.named_steps['select']\n",
        "feature_mask = selector.get_support()\n",
        "selected_features = [feature for feature, keep in zip(feature_names, feature_mask) if keep]\n",
        "\n",
        "print(\"Selected features:\", list(selected_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cd74294-b946-4bd4-89bd-2089282b11fe",
      "metadata": {
        "id": "4cd74294-b946-4bd4-89bd-2089282b11fe"
      },
      "outputs": [],
      "source": [
        "#Train model on \"selected_features\"\n",
        "best_model.fit(train_X[selected_features], train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2c4ecf7-0e87-42fa-b109-0b6ecf95d814",
      "metadata": {
        "id": "f2c4ecf7-0e87-42fa-b109-0b6ecf95d814"
      },
      "outputs": [],
      "source": [
        "#Make Predictions on Training Data using \"best_variables\"\n",
        "train_pred = best_model.predict(train_X[selected_features])\n",
        "train_residuals = train_y - train_pred\n",
        "\n",
        "result = pd.DataFrame({'Predicted':train_pred ,'Actual': train_y,'Residual': train_y - train_pred})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb352807-4022-44ec-9e5a-14dd1e6481ef",
      "metadata": {
        "id": "bb352807-4022-44ec-9e5a-14dd1e6481ef"
      },
      "outputs": [],
      "source": [
        "# Denormalize predictions and actuals\n",
        "train_pred_orig = y_scaler.inverse_transform(train_pred.reshape(-1, 1))\n",
        "train_y_orig = y_scaler.inverse_transform(train_y.values.reshape(-1, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9520454a-1e64-4145-aea8-7cb882ab2460",
      "metadata": {
        "id": "9520454a-1e64-4145-aea8-7cb882ab2460"
      },
      "outputs": [],
      "source": [
        "#Evaluate the Model\n",
        "regressionSummary(train_y_orig ,train_pred_orig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41da7bf4-d324-41f2-8f7f-46053e6d441d",
      "metadata": {
        "id": "41da7bf4-d324-41f2-8f7f-46053e6d441d"
      },
      "outputs": [],
      "source": [
        "# Visualization – Training Data\n",
        "train_y_orig = train_y_orig.ravel()\n",
        "train_pred_orig = train_pred_orig.ravel()\n",
        "\n",
        "# Plotting actual vs predicted values\n",
        "plt.figure()\n",
        "sns.scatterplot(x=train_y_orig, y=train_pred_orig, alpha=0.6, color='skyblue', edgecolor='k')\n",
        "\n",
        "# Reference line (perfect prediction line)\n",
        "min_val = min(train_y_orig.min(), train_pred_orig.min())\n",
        "max_val = max(train_y_orig.max(), train_pred_orig.max())\n",
        "plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect Fit')\n",
        "\n",
        "# Labels and title\n",
        "plt.title(\"Training Data: Actual vs Predicted (KNN)\", fontsize=14)\n",
        "plt.xlabel(\"Actual House Price\", fontsize=12)\n",
        "plt.ylabel(\"Predicted House Price\", fontsize=12)\n",
        "\n",
        "# Additional plot features\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6c07a3e-16ef-4196-8180-4431c39964fd",
      "metadata": {
        "id": "e6c07a3e-16ef-4196-8180-4431c39964fd"
      },
      "outputs": [],
      "source": [
        "# Recalculate residuals in original scale\n",
        "train_residuals_orig = train_y_orig - train_pred_orig\n",
        "\n",
        "# Create a result DataFrame (optional, for plotting consistency)\n",
        "result = pd.DataFrame({\n",
        "    'Actual': train_y_orig,\n",
        "    'Predicted': train_pred_orig,\n",
        "    'Residual': train_residuals_orig\n",
        "})\n",
        "\n",
        "# Plot Actual Training Data Distribution\n",
        "plt.figure()\n",
        "sns.histplot(result['Actual'], kde=True, color='skyblue')\n",
        "plt.xlabel('House Price per Unit Area', fontsize=12)\n",
        "plt.title(\"Actual Training Data Distribution - KNN\", fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot Predicted Training Data Distribution\n",
        "plt.figure()\n",
        "sns.histplot(result['Predicted'], kde=True, color='skyblue')\n",
        "plt.xlabel('House Price per Unit Area', fontsize=12)\n",
        "plt.title(\"Predicted Training Data Distribution - KNN\", fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot Training Residuals Distribution\n",
        "plt.figure()\n",
        "sns.histplot(result['Residual'], kde=True, color='skyblue')\n",
        "plt.xlabel('Residual', fontsize=12)\n",
        "plt.title(\"Training Residuals Distribution - KNN\", fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49bb9856-6eea-4c18-b636-43f35718aaad",
      "metadata": {
        "id": "49bb9856-6eea-4c18-b636-43f35718aaad"
      },
      "outputs": [],
      "source": [
        "#Make Predictions on Validation Data using \"best_variables\"\n",
        "valid_pred = best_model.predict(valid_X[selected_features])\n",
        "valid_residuals = valid_y - valid_pred\n",
        "\n",
        "result1 = pd.DataFrame({'Predicted':valid_pred ,'Actual': valid_y,'Residual': valid_y - valid_pred})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c8d25de-d3d8-4007-a30e-1e6f49f094f2",
      "metadata": {
        "id": "5c8d25de-d3d8-4007-a30e-1e6f49f094f2"
      },
      "outputs": [],
      "source": [
        "# Denormalize predictions and actuals\n",
        "valid_pred_orig = y_scaler.inverse_transform(valid_pred.reshape(-1, 1))\n",
        "valid_y_orig = y_scaler.inverse_transform(valid_y.values.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef3d6aca-58fb-429d-bc00-12154e90eff9",
      "metadata": {
        "id": "ef3d6aca-58fb-429d-bc00-12154e90eff9"
      },
      "outputs": [],
      "source": [
        "#Evaluate the Model\n",
        "regressionSummary(valid_y_orig, valid_pred_orig )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f623fa2-e8ad-4d0b-be5e-99f4da1c8cfe",
      "metadata": {
        "id": "2f623fa2-e8ad-4d0b-be5e-99f4da1c8cfe"
      },
      "outputs": [],
      "source": [
        "# Ensure both arrays are reshaped to 1D if needed\n",
        "valid_y_orig = valid_y_orig.ravel()\n",
        "valid_pred_orig = valid_pred_orig.ravel()\n",
        "# Recalculate residuals in original scale\n",
        "valid_residuals_orig = valid_y_orig - valid_pred_orig\n",
        "\n",
        "# Create a result DataFrame for validation\n",
        "result1 = pd.DataFrame({\n",
        "    'Actual': valid_y_orig,\n",
        "    'Predicted': valid_pred_orig,\n",
        "    'Residual': valid_residuals_orig\n",
        "})\n",
        "\n",
        "# Plot 1: Actual vs Predicted for Validation Data\n",
        "plt.figure()\n",
        "sns.scatterplot(x=valid_y_orig, y=valid_pred_orig, alpha=0.6, color='skyblue', edgecolor='k')\n",
        "\n",
        "# Perfect prediction line\n",
        "min_val = min(valid_y_orig.min(), valid_pred_orig.min())\n",
        "max_val = max(valid_y_orig.max(), valid_pred_orig.max())\n",
        "plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect Fit')\n",
        "\n",
        "plt.title(\"Validation Data: Actual vs Predicted (KNN)\", fontsize=14)\n",
        "plt.xlabel(\"Actual House Price\", fontsize=12)\n",
        "plt.ylabel(\"Predicted House Price\", fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e136324-4ccd-4014-b923-dedd3111a4a1",
      "metadata": {
        "id": "6e136324-4ccd-4014-b923-dedd3111a4a1"
      },
      "outputs": [],
      "source": [
        "# Plot Actual Validation Data Distribution\n",
        "plt.figure()\n",
        "sns.histplot(result1['Actual'], kde=True, color='skyblue')\n",
        "plt.xlabel('House Price per Unit Area', fontsize=12)\n",
        "plt.title(\"Actual Validation Data Distribution - KNN\", fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot Predicted Validation Data Distribution\n",
        "plt.figure()\n",
        "sns.histplot(result1['Predicted'], kde=True, color='skyblue')\n",
        "plt.xlabel('House Price per Unit Area', fontsize=12)\n",
        "plt.title(\"Predicted Validation Data Distribution - KNN\", fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot Residuals Distribution (Validation)\n",
        "plt.figure()\n",
        "sns.histplot(result1['Residual'], kde=True, color='skyblue')\n",
        "plt.xlabel('Residual', fontsize=12)\n",
        "plt.title(\"Validation Residuals Distribution - KNN\", fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1352190-46bd-4792-bc58-3f89979d100f",
      "metadata": {
        "id": "f1352190-46bd-4792-bc58-3f89979d100f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}